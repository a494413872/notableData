---
attachments: [Clipboard_2021-03-05-14-22-47.png, Clipboard_2021-03-05-14-26-45.png]
tags: [java/jvm]
title: 内存屏障
created: '2021-03-05T06:01:59.425Z'
modified: '2021-03-05T13:22:13.987Z'
---

# 内存屏障

内存屏障，内存栅栏其实是一个东西的不同叫法，要想理解内存屏障，需要先理解cpu的工作原理。
## CPU 缓存
cpu执行命令是很快的，而cpu直接访问内存是比较慢的，这个速度差是不可能接受的，所以每个cpu都有自己的缓存（缓存也分多级，这里不深究，就抽象为缓存的概念），cpu会先尝试去缓存中读取数据，获取不到的时候才会去读取内存。
## cache line 缓存条目
说到cpu缓存就不得不说一下缓存本身的结构，缓存本身是由类似于hashmap的结构，由一个个桶组成，而桶里面又是一个链表结构，而每一个节点都是一个cache line。
![](@attachment/Clipboard_2021-03-05-14-22-47.png)
一个cache line一般是64 bytes，假设程序中读取某一个int变量，CPU并不是只从主存中读取4个字节，而是会一次性读取64个字节，然后放到cpu cache中。因为往往紧挨着的数据，更有可能在接下来会被使用到。比如遍历一个数组，因为数组空间是连续的，所以并不是每次取数组中的元素都要从主存中去拿，第一次从主存把数据放到cache line中，后续访问的数据很有可能已经在cache中了。
### 缓存条目（cache line）近一步可以分为三个部分：
![](@attachment/Clipboard_2021-03-05-14-26-45.png)
CPU访问内存时，会通过内存地址解码的三个数据：index（桶编号）、tag（缓存条目的相对编号）、offset（变量在缓存条目中的位置偏移）来获取高速缓存中对应的数据。
这时候可以看到Flag这个标识了，然后就可以引出了状态值的概念，然后就可以引出我们所说的MSEI协议了。
## EMSI 协议
MSEI其实就是四种状态首字母的简写，就代表上面缓存条目（cache line）的四种状态，分别是：
状态|描述
-|-
M|修改 (Modified)	该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。
E|独享、互斥 (Exclusive)	该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。
S|共享 (Shared)	该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。
I|无效 (Invalid)	该Cache line无效。

举例说明一下:假设cpu有A,B两个core，当他们都读取一个值x的时候，在A，B之中这个值的状态都是S。这时候如果A要对x进行修改，会先通知B，并且把自身的x设置为E，B收到通知会回复A收到并把自身的x设置为I，A收到B的回复之后，会再把cache line的falg设置为M。

## EMSI 带来的问题
上一节我们说到了MESI缓存一致性协议是如何实现的，实际上就是在进行写的时候只有一个能写，告诉别的核中的缓存都是过期的需要从最新的里面读；在读的时候大家可以一起读。虽然有了这个协议但是仔细分析一下会有这样一种情况的发生：
首先有一个变量在多个核中的缓存存在，那么这个缓存的状态是S（shared）共享的，现在核A想要修改这个变量，首先核A会向所有拥有相同缓存的其他核发送一个请求，告诉其他核中的缓存是I（Invalid）无效的，其他核收到这个信息将自己核中的缓存状态设置为无效之后，返回一个设置完成的消息，这个核A收到这个无效状态修改的消息后，再把自己的状态改为E（Exclusive）独享的，然后修改为M（Modified）进行缓存修改。
乍看之下没什么问题，但是在核A等待其他核返回无效状态修改的消息返回的时候是一直在阻塞没事情干的，这对于高性能的CPU是不能容忍的，所以这个时候设计者引入了写缓存（Store Buffer）的无效化队列（Invalidate Queue）。

## 写缓存（Store Buffer）
写缓存是一个容量极小的高速存储部,每个core独享，用来存储写命令。比如当核A的写命令发出后，会先放在写缓存，然后通知B，在等待B回复期间，cpu继续执行其他命令，等到B回复之后，然后再从写缓存中取出执行。
写缓存会带来一个问题，由于写缓存的存在，当A还没有收到B的回复，并执行完修改的时候，其实cache line里面的数据也不是最新的。所以设计人员选择支持从写缓存里面读取数据，如果取不到就取cache line的数据。这个策略被叫做Store Forwarding。

## 无效化队列（Invalidate Queue）
无效化队列是被通知方比如核心B，为了快速回应A而设计的，当收到A的命令后，B先将无效操作放到无效化队列里面，然后就去回复A，然后再回头来处理队里里面的命令。把缓存里面的标识设置为无效。

### PS:[指令重排」分为两种类型，一种是「主动的」，编译器会主动重排代码使得特定的cpu执行更快。另外一个类型是「被动的」，为了异步化指令的执行，引入Store Buffer和Invalidate Queue，却导致了「指令顺序改变」的副作用。

## 内存屏障
Store Buffer和Invalidate Queue会带来可见性问题，也就是读和写不能实时更新到其他核。所以需要引入内存屏障，内存屏障包括下面几种
读屏障：强制将Invalidate Queue中的内容处理完毕
写屏障：强制将Store Buffer中的内容写入到缓存中或者将该指令之后的写操作写入store buffer直到之前的内容被刷入到缓存中


## 与java的联系
java为了封装CPU执行的复杂性，对内存屏障的操作进行了抽象来保证程序的正确性，但是并不代表实际CPU的执行，而是同样的效果。
java的屏障有4种
名称|作用
-|-
LoadLoad Barriers |指令 Load1; LoadLoad; Load2 保证了 Load1 先于 Load2 和后续所有的 load 指令加载数据
StoreStore Barriers |指令 Store1; StoreStore; Store2 保证了 Store1 的数据先于 Store2 及后续 store 指令的数据对其他处理器可见（刷新到内存）
LoadStore Barriers |指令 Load1; LoadStore; Store2 保证了 Load1 的加载数据先于 Store2 及后续 store 指令刷新数据到主内存
StoreLoad Barriers | 指令 Store1; StoreLoad; Load2 保证了 Store1 的数据对其他处理器可见（刷新数据到主内存）先于 Load2 及后续的 load 指令加载数据

## 与volatile的联系
- 在每个volatile写操作的前面插入一个StoreStore屏障，保证volatile写操作前面的Store Buffer队列中的操作都已经刷新到缓存中，防止前面的写操作与volatile写操作发生指令重排。
- 在每个volatile写操作的后面插入一个StoreLoad屏障，保证后面的其他写/读操作前面的Store Buffer队列中的操作都已经刷新到缓存中（也就是volatile写操作），防止后面的其他写/读操作与volatile写操作发生指令重排。
- 在每个volatile读操作的前面插入一个LoadLoad屏障，保证后面的其他读操作的无效化队列已经将volatile无效刷新到缓存中，防止后面的读操作与volatile读操作发生指令重排。
- 在每个volatile读操作的后面插入一个LoadStore屏障，保证后面的其他写操作的无效化队列已经将volatile无效刷新到缓存中，防止后面的写操作与volatile读操作发生指令重排。



